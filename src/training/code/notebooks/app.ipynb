{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbd_CJ5lJQvp",
    "outputId": "0edf74e3-a632-438d-c529-89939181c0ae",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: peft in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (0.15.1)\n",
      "Requirement already satisfied: datasets in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (3.2.0)\n",
      "Requirement already satisfied: numba in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (0.61.0)\n",
      "Requirement already satisfied: bitsandbytes in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (0.42.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from peft) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: transformers in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from peft) (4.48.3)\n",
      "Requirement already satisfied: tqdm in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from peft) (1.3.0)\n",
      "Requirement already satisfied: safetensors in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from peft) (0.5.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from peft) (0.28.1)\n",
      "Requirement already satisfied: filelock in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from datasets) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from numba) (0.44.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: networkx in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from torch>=1.13.0->peft) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from torch>=1.13.0->peft) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from transformers->peft) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/koval/.pyenv/versions/3.13.0/lib/python3.13/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers accelerate peft bitsandbytes datasets torch mlflow -q\n",
    "#!pip install flash-attn --no-build-isolation -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlflow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SQrrYR2IeZM0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "from inspect import signature\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import PartialState\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, recall_score, \\\n",
    "                            confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorWithPadding,\n",
    "    PreTrainedModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    TrainerCallback\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"deepseek-ai/DeepSeek-Coder-V2-Lite-Base\"\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To not hang for an hour if no connection could be established\n",
    "mlflow.environment_variables.MLFLOW_HTTP_REQUEST_TIMEOUT = 10\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://nondecayed-laurinda-pleiophyllous.ngrok-free.dev\")\n",
    "\n",
    "mlflow.set_experiment(\"MLFlow and metrics interpretability testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ub4ZJGgnrMrX"
   },
   "source": [
    "## Google drive mount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_unmqCYrSCs"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "oZwkz2wNeZM0",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZ4yFI7kJQvs"
   },
   "outputs": [],
   "source": [
    "BASE_LOCATION: Path = Path(__file__).parent\n",
    "\n",
    "\n",
    "# Datasets\n",
    "DATASET_PATHS = {\n",
    "    \"local\": {\n",
    "        \"train\": BASE_LOCATION.parents[3] / \"datasets/data/train_set.csv\",\n",
    "        \"eval\": BASE_LOCATION.parents[3] / \"datasets/data/eval_set.csv\",\n",
    "    },\n",
    "    \"local_two\": {\"train\": \"train_set.csv\", \"eval\": \"eval_set.csv\"},\n",
    "    \"local_three\": {\n",
    "        \"train\": \"drive/MyDrive/fine_tuning/train_set.csv\",\n",
    "        \"eval\": \"drive/MyDrive/fine_tuning/eval_set.csv\",\n",
    "    },\n",
    "    \"kaggle\": {\n",
    "        \"train\": \"/kaggle/input/python-codes-time-complexity/train_set.csv\",\n",
    "        \"eval\": \"/kaggle/input/python-codes-time-complexity/eval_set.csv\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_datasets(dataset_paths=DATASET_PATHS):\n",
    "    for path in dataset_paths:\n",
    "        if os.path.exists(dataset_paths[path][\"train\"]) and os.path.exists(dataset_paths[path][\"eval\"]):\n",
    "            print(\"Data found!\")\n",
    "            return dataset_paths[path][\"train\"], dataset_paths[path][\"eval\"]\n",
    "\n",
    "    return FileNotFoundError(f\"Datasets do not exist in the current paths: {dataset_paths}\")\n",
    "\n",
    "train_set_path, eval_set_path = upload_datasets()\n",
    "\n",
    "train_set = load_dataset(\"csv\", data_files=train_set_path)[\"train\"]\n",
    "eval_set = load_dataset(\"csv\", data_files=eval_set_path)[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "H0DYqksrJQvt",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "sCgyImnMJQvt",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Hierarchy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFggTBarJQvt"
   },
   "outputs": [],
   "source": [
    "LABELS_HIERARCHY = {\n",
    "    'constant': 1,\n",
    "    'logn': 2,\n",
    "    'linear': 3,\n",
    "    'nlogn': 4,\n",
    "    'quadratic': 5,\n",
    "    'cubic': 6,\n",
    "    'np': 7\n",
    "}\n",
    "\n",
    "N_CLASSES = len(LABELS_HIERARCHY)\n",
    "\n",
    "# Hierarchy score\n",
    "def hc_score(y_true, y_pred, n_classes=N_CLASSES):\n",
    "    assert len(y_true) == len(y_pred), (\n",
    "        f\"The amount of y_true labels: {len(y_true)} does not equal to the amount of y_pred: {len(y_pred)}.\"\n",
    "    )\n",
    "\n",
    "    n_samples = len(y_true)\n",
    "\n",
    "    return (np.sum(np.abs(y_pred - y_true)) / n_classes) / n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    # Make preds & labels global for access in callbacks\n",
    "    global last_preds, last_labels\n",
    "\n",
    "    logits, labels = eval_preds\n",
    "    preds = np.argmax(logits[0], axis=-1) if isinstance(logits, tuple) else np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Save for callbacking\n",
    "    last_preds, last_labels = preds, labels\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=preds)\n",
    "    \n",
    "    # Calculate F-1 Macro\n",
    "    f1_macro_score = f1_score(y_true=labels, y_pred=preds, average=\"macro\")\n",
    "\n",
    "    # Calculate per-class recall\n",
    "    recall_scores = recall_score(y_true=labels, y_pred=preds, average=None, labels=[0, 1, 4, 5, 2, 3, 6]) # reorder labels here because of how labelEncoder encodes the labels in not complexity-wise ascending order\n",
    "    recall_per_class = {}\n",
    "\n",
    "    # Zip label: score into a dict\n",
    "    for label, score in zip(LABELS_HIERARCHY.keys(), recall_scores):\n",
    "        recall_per_class[label] = np.round(score, 2)\n",
    "\n",
    "    # Calculate Hierarchy Score\n",
    "    hierarchy_score = hc_score(y_true=labels, y_pred=preds)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1_macro\": f1_macro_score,\n",
    "        \"recall_score\": recall_per_class,\n",
    "        \"hierarchy_score\": hierarchy_score,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval metric callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrixCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        if last_preds is not None:\n",
    "            # Calculate confusion matrix\n",
    "            disp = ConfusionMatrixDisplay.from_predictions(y_true=last_labels, y_pred=last_preds, labels=[0, 1, 4, 5, 2, 3, 6], # reorder labels here because of how labelEncoder encodes the labels in not complexity-wise ascending order\n",
    "                                                            display_labels=[\"O(1)\", \"O(logn)\", \"O(n)\",\"O(nlogn)\",\n",
    "                                                            \"O(n^2)\", \"O(n^3)\",\"np\",])\n",
    "            # Get fig and axes\n",
    "            fig = disp.figure_\n",
    "            ax = disp.ax_\n",
    "\n",
    "            # Make slightly wider to fit xtick labels\n",
    "            fig.set_size_inches(10, 5)\n",
    "            fig.tight_layout()\n",
    "            \n",
    "            #plt.show()\n",
    "\n",
    "            # Save as png and Log to MLFlow\n",
    "            fig.savefig(\"confusion_matrix.png\")\n",
    "            # Close and unregister, so that it doesn't print\n",
    "            plt.close(fig)\n",
    "            mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "\n",
    "\n",
    "class RecallScoreCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        # Parse recall scores\n",
    "        recall_scores = kwargs['metrics']['eval_recall_score']\n",
    "\n",
    "        # Create a barplot\n",
    "        ax = sns.barplot(x=np.array(list(recall_scores.keys())),\n",
    "                    y=np.array(list(recall_scores.values())),\n",
    "                   )\n",
    "        # Add labels\n",
    "        ax.set_xlabel(xlabel=\"Complexity\", labelpad=20, fontsize=14)\n",
    "        ax.set_ylabel(ylabel=\"Recall score\", labelpad=20, fontsize=14)\n",
    "        \n",
    "        #plt.show()\n",
    "        \n",
    "        # Save as png and log to MLFLow\n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig(\"recall_per_score.png\")\n",
    "        # Close and unregister, so that it doesn't print\n",
    "        plt.close(fig)\n",
    "        mlflow.log_artifact(\"recall_per_score.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Lr46o1ghJQvt",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5Hb02FFeZM0"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "# Setting up Label Encoder\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(train_set[\"complexity\"])\n",
    "\n",
    "def tokenize_data(data, tokenizer):\n",
    "    # Tokenizing\n",
    "    tokenized = tokenizer(\n",
    "        data[\"code\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "    tokenized[\"labels\"] = labelEncoder.transform(data[\"complexity\"])\n",
    "    return tokenized\n",
    "\n",
    "def set_tokenizer(checkpoint):\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint, pad_token=\"<pad>\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {checkpoint}: {e}\")\n",
    "        checkpoint = \"-\".join(checkpoint.split(\"-\")[:2])\n",
    "        tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        print(f\"Falling back to {checkpoint}\")\n",
    "\n",
    "    X_train = train_set.map(\n",
    "        lambda x: tokenize_data(x, tokenizer),\n",
    "        batched=True,\n",
    "        remove_columns=train_set.column_names,\n",
    "    )\n",
    "    X_eval = eval_set.map(\n",
    "        lambda x: tokenize_data(x, tokenizer),\n",
    "        batched=True,\n",
    "        remove_columns=eval_set.column_names,\n",
    "    )\n",
    "\n",
    "    # Data Collator\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    return tokenizer, data_collator, X_train, X_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, data_collator, train_set, eval_set = set_tokenizer(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model loading\n",
    "def set_model(checkpoint, tokenizer, ModelType=AutoModel):\n",
    "    # Setup bitsandbytes quantization config\n",
    "    \"\"\"quant_config = setup_bnb_config()\"\"\"\n",
    "\n",
    "    # Load a pretrained model\n",
    "    model = ModelType.from_pretrained(\n",
    "        checkpoint,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        num_labels=N_CLASSES,\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\"\n",
    "        #device_map=PartialState().process_index,\n",
    "        #quantization_config=quant_config,\n",
    "        #attn_implementation=\"flash_attention_2\", Only for newer models\n",
    "    )\n",
    "\n",
    "    # Accomodating the size of the token embeddings for the potential missing <pad> token\n",
    "    model.resize_token_embeddings(len(tokenizer), mean_resizing=False)\n",
    "\n",
    "    # Passing the pad token id to the model config\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom head for Deepseek v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom classifier head\n",
    "class DeepseekV2ForSequenceClassification(PreTrainedModel):\n",
    "    config_class = AutoConfig\n",
    "\n",
    "    def __init__(self, base_model, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.model = base_model\n",
    "\n",
    "        self.dense = nn.Linear(config.n_embd, config.num_labels, bias=False, dtype=self.model.dtype)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def get_input_embeddings(self):\n",
    "        return self.model.config.n_embd\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, *args, **kwargs):\n",
    "        outputs = self.model(input_ids, attention_mask)\n",
    "\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        logits = self.dense(hidden_states)\n",
    "\n",
    "        # Batch size\n",
    "        if input_ids is not None:\n",
    "            batch_size = input_ids.shape[0]\n",
    "\n",
    "        # If padding token id is not configured and the batch size is > 1\n",
    "        if self.config.pad_token_id is None and batch_size != 1:\n",
    "            raise ValueError(\"Cannot handle batch sizes > 1 if no padding token is defined.\")\n",
    "        # If padding token id is not configured\n",
    "        if self.config.pad_token_id is None:\n",
    "            last_non_pad_token = -1\n",
    "        # if encoded inputs exist => find the last non padded token to pool data from\n",
    "        elif input_ids is not None:\n",
    "            non_pad_mask = (input_ids != self.config.pad_token_id).to(logits.device, dtype=torch.int32)\n",
    "            token_indices = torch.arange(input_ids.shape[-1], device=logits.device, dtype=torch.int32)\n",
    "            last_non_pad_token = (token_indices * non_pad_mask).argmax(-1)\n",
    "\n",
    "        # Pooling logits from the last non padded token across the batches\n",
    "        pooled_logits = logits[torch.arange(batch_size, device=logits.device), last_non_pad_token]\n",
    "\n",
    "        # Calculating loss if labels are provided\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = self.loss_function(\n",
    "                logits=logits,\n",
    "                labels=labels,\n",
    "                pooled_logits=pooled_logits,\n",
    "                config=self.config,\n",
    "            )\n",
    "\n",
    "        return SequenceClassifierOutput(loss=loss, logits=pooled_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization (BnB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bitsandbytes (Quantization)\n",
    "def setup_bnb_config():\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_storage=torch.bfloat16,\n",
    "    )\n",
    "    return quant_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    # target_modules = ['q_proj', 'v_proj'], # Qwen\n",
    "    target_modules=\"all-linear\",  # Heavy, universal\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",  # might not work with this on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = set_model(checkpoint, tokenizer, AutoModelForSequenceClassification)\n",
    "# model = DeepseekV2ForSequenceClassification(model, model.config)\n",
    "#model = get_peft_model(model=model, peft_config=peft_config)\n",
    "\n",
    "#print(f\"Model: {model}\")\n",
    "# print(f\"Model config: {model.config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrainingArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"training_results/{checkpoint}/\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    # eval_steps=5,\n",
    "    # learning_rate=2e-4, # Testing\n",
    "    bf16=True,\n",
    "    #gradient_checkpointing=True,\n",
    "    report_to=\"mlflow\",\n",
    "    num_train_epochs=3,\n",
    "    #warmup_steps=100,  # Testing\n",
    "    label_names=[\"labels\"],\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=1,\n",
    "    load_best_model_at_end=True,\n",
    "    run_name=\"full data 3 epochs\",\n",
    "    #deepspeed=\"configs/ds_config.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=eval_set,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[ConfusionMatrixCallback(), RecallScoreCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "XPRanUW6eZM2",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "eval_metrics = trainer.evaluate(eval_dataset=eval_set)\n",
    "trainer.save_metrics(split=\"eval\", metrics=eval_metrics)\n",
    "\n",
    "# Saving the full model\n",
    "if trainer.is_fsdp_enabled:\n",
    "    trainer.accelerator.state.fsdp_plugin.set_state_dict_type(\"FULL_STATE_DICT\")\n",
    "\n",
    "trainer.save_model(f\"./best_model/{checkpoint}/\")\n",
    "print(\"The best model was saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "1EBAkLR5JQvx",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Flushing CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6fYTw2_JQvx"
   },
   "outputs": [],
   "source": [
    "!pip install GPUtil\n",
    "\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "\n",
    "free_gpu_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "1tOXZ8Z_JQvx",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Drjxr-AY0Vn"
   },
   "outputs": [],
   "source": [
    "device = torch.cuda.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b67a1iLHJQvx"
   },
   "outputs": [],
   "source": [
    "tokenizer, data_collator, train_set, eval_set = set_tokenizer(checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NNAeFmlJQvx"
   },
   "outputs": [],
   "source": [
    "def predict(inputs):\n",
    "    # Tokenizing inputs\n",
    "    test_sample = tokenizer(inputs, return_tensors='pt', padding=True, truncation=True)\n",
    "    inputs = Dataset.from_dict({key: value.to(model.device) for key, value in test_sample.items()})\n",
    "\n",
    "    # Predicting & decoding inputs\n",
    "    preds = trainer.predict(test_dataset=inputs)\n",
    "    preds = labelEncoder.inverse_transform(y=np.ravel(np.argmax(preds.predictions[0], axis=-1)))\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkoEDmUMV1EU"
   },
   "outputs": [],
   "source": [
    "test_sample = \"\"\"\n",
    "class Solution:\n",
    "    def topKFrequent(self, nums: List[int], k: int) -> List[int]:\n",
    "        count = {}\n",
    "        for num in nums:\n",
    "            count[num] = 1 + count.get(num, 0)\n",
    "\n",
    "        arr = []\n",
    "        for num, cnt in count.items():\n",
    "            arr.append([cnt, num])\n",
    "        arr.sort()\n",
    "\n",
    "        res = []\n",
    "        while len(res) < k:\n",
    "            res.append(arr.pop()[1])\n",
    "        return res\n",
    "        \"\"\"\n",
    "\n",
    "predict(test_sample)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6562833,
     "sourceId": 10696892,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
